{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c633015-7ebb-4ac6-b2b5-6352e891b0b4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-06T01:02:59.473368Z",
     "iopub.status.busy": "2025-11-06T01:02:59.473172Z",
     "iopub.status.idle": "2025-11-06T01:03:00.608496Z",
     "shell.execute_reply": "2025-11-06T01:03:00.608049Z",
     "shell.execute_reply.started": "2025-11-06T01:02:59.473353Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepencoder_sam import build_sam_vit_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda37b76-4086-4474-8402-f05028f8f636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T01:03:01.269787Z",
     "iopub.status.busy": "2025-11-06T01:03:01.269480Z",
     "iopub.status.idle": "2025-11-06T01:03:01.809187Z",
     "shell.execute_reply": "2025-11-06T01:03:01.808719Z",
     "shell.execute_reply.started": "2025-11-06T01:03:01.269767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sam_model = build_sam_vit_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03dbaaf4-23e5-4ae9-9f41-b1b153dfd65a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T01:03:02.872211Z",
     "iopub.status.busy": "2025-11-06T01:03:02.871987Z",
     "iopub.status.idle": "2025-11-06T01:03:02.875715Z",
     "shell.execute_reply": "2025-11-06T01:03:02.875197Z",
     "shell.execute_reply.started": "2025-11-06T01:03:02.872195Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sam_model_state_dict = sam_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a752c6e-17e2-4a05-949e-dd2bcb5ac1f1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-06T01:03:04.696920Z",
     "iopub.status.busy": "2025-11-06T01:03:04.696711Z",
     "iopub.status.idle": "2025-11-06T01:03:04.701284Z",
     "shell.execute_reply": "2025-11-06T01:03:04.700859Z",
     "shell.execute_reply.started": "2025-11-06T01:03:04.696903Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.attn.proj.bias, torch.Size([768])\n",
      "blocks.0.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.0.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.0.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.0.attn.rel_pos_h, torch.Size([27, 64])\n",
      "blocks.0.attn.rel_pos_w, torch.Size([27, 64])\n",
      "blocks.0.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.0.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.0.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.0.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.0.norm1.bias, torch.Size([768])\n",
      "blocks.0.norm1.weight, torch.Size([768])\n",
      "blocks.0.norm2.bias, torch.Size([768])\n",
      "blocks.0.norm2.weight, torch.Size([768])\n",
      "blocks.1.attn.proj.bias, torch.Size([768])\n",
      "blocks.1.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.1.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.1.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.1.attn.rel_pos_h, torch.Size([27, 64])\n",
      "blocks.1.attn.rel_pos_w, torch.Size([27, 64])\n",
      "blocks.1.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.1.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.1.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.1.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.1.norm1.bias, torch.Size([768])\n",
      "blocks.1.norm1.weight, torch.Size([768])\n",
      "blocks.1.norm2.bias, torch.Size([768])\n",
      "blocks.1.norm2.weight, torch.Size([768])\n",
      "blocks.10.attn.proj.bias, torch.Size([768])\n",
      "blocks.10.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.10.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.10.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.10.attn.rel_pos_h, torch.Size([27, 64])\n",
      "blocks.10.attn.rel_pos_w, torch.Size([27, 64])\n",
      "blocks.10.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.10.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.10.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.10.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.10.norm1.bias, torch.Size([768])\n",
      "blocks.10.norm1.weight, torch.Size([768])\n",
      "blocks.10.norm2.bias, torch.Size([768])\n",
      "blocks.10.norm2.weight, torch.Size([768])\n",
      "blocks.11.attn.proj.bias, torch.Size([768])\n",
      "blocks.11.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.11.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.11.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.11.attn.rel_pos_h, torch.Size([127, 64])\n",
      "blocks.11.attn.rel_pos_w, torch.Size([127, 64])\n",
      "blocks.11.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.11.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.11.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.11.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.11.norm1.bias, torch.Size([768])\n",
      "blocks.11.norm1.weight, torch.Size([768])\n",
      "blocks.11.norm2.bias, torch.Size([768])\n",
      "blocks.11.norm2.weight, torch.Size([768])\n",
      "blocks.2.attn.proj.bias, torch.Size([768])\n",
      "blocks.2.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.2.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.2.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.2.attn.rel_pos_h, torch.Size([127, 64])\n",
      "blocks.2.attn.rel_pos_w, torch.Size([127, 64])\n",
      "blocks.2.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.2.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.2.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.2.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.2.norm1.bias, torch.Size([768])\n",
      "blocks.2.norm1.weight, torch.Size([768])\n",
      "blocks.2.norm2.bias, torch.Size([768])\n",
      "blocks.2.norm2.weight, torch.Size([768])\n",
      "blocks.3.attn.proj.bias, torch.Size([768])\n",
      "blocks.3.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.3.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.3.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.3.attn.rel_pos_h, torch.Size([27, 64])\n",
      "blocks.3.attn.rel_pos_w, torch.Size([27, 64])\n",
      "blocks.3.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.3.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.3.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.3.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.3.norm1.bias, torch.Size([768])\n",
      "blocks.3.norm1.weight, torch.Size([768])\n",
      "blocks.3.norm2.bias, torch.Size([768])\n",
      "blocks.3.norm2.weight, torch.Size([768])\n",
      "blocks.4.attn.proj.bias, torch.Size([768])\n",
      "blocks.4.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.4.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.4.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.4.attn.rel_pos_h, torch.Size([27, 64])\n",
      "blocks.4.attn.rel_pos_w, torch.Size([27, 64])\n",
      "blocks.4.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.4.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.4.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.4.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.4.norm1.bias, torch.Size([768])\n",
      "blocks.4.norm1.weight, torch.Size([768])\n",
      "blocks.4.norm2.bias, torch.Size([768])\n",
      "blocks.4.norm2.weight, torch.Size([768])\n",
      "blocks.5.attn.proj.bias, torch.Size([768])\n",
      "blocks.5.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.5.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.5.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.5.attn.rel_pos_h, torch.Size([127, 64])\n",
      "blocks.5.attn.rel_pos_w, torch.Size([127, 64])\n",
      "blocks.5.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.5.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.5.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.5.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.5.norm1.bias, torch.Size([768])\n",
      "blocks.5.norm1.weight, torch.Size([768])\n",
      "blocks.5.norm2.bias, torch.Size([768])\n",
      "blocks.5.norm2.weight, torch.Size([768])\n",
      "blocks.6.attn.proj.bias, torch.Size([768])\n",
      "blocks.6.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.6.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.6.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.6.attn.rel_pos_h, torch.Size([27, 64])\n",
      "blocks.6.attn.rel_pos_w, torch.Size([27, 64])\n",
      "blocks.6.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.6.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.6.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.6.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.6.norm1.bias, torch.Size([768])\n",
      "blocks.6.norm1.weight, torch.Size([768])\n",
      "blocks.6.norm2.bias, torch.Size([768])\n",
      "blocks.6.norm2.weight, torch.Size([768])\n",
      "blocks.7.attn.proj.bias, torch.Size([768])\n",
      "blocks.7.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.7.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.7.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.7.attn.rel_pos_h, torch.Size([27, 64])\n",
      "blocks.7.attn.rel_pos_w, torch.Size([27, 64])\n",
      "blocks.7.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.7.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.7.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.7.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.7.norm1.bias, torch.Size([768])\n",
      "blocks.7.norm1.weight, torch.Size([768])\n",
      "blocks.7.norm2.bias, torch.Size([768])\n",
      "blocks.7.norm2.weight, torch.Size([768])\n",
      "blocks.8.attn.proj.bias, torch.Size([768])\n",
      "blocks.8.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.8.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.8.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.8.attn.rel_pos_h, torch.Size([127, 64])\n",
      "blocks.8.attn.rel_pos_w, torch.Size([127, 64])\n",
      "blocks.8.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.8.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.8.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.8.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.8.norm1.bias, torch.Size([768])\n",
      "blocks.8.norm1.weight, torch.Size([768])\n",
      "blocks.8.norm2.bias, torch.Size([768])\n",
      "blocks.8.norm2.weight, torch.Size([768])\n",
      "blocks.9.attn.proj.bias, torch.Size([768])\n",
      "blocks.9.attn.proj.weight, torch.Size([768, 768])\n",
      "blocks.9.attn.qkv.bias, torch.Size([2304])\n",
      "blocks.9.attn.qkv.weight, torch.Size([2304, 768])\n",
      "blocks.9.attn.rel_pos_h, torch.Size([27, 64])\n",
      "blocks.9.attn.rel_pos_w, torch.Size([27, 64])\n",
      "blocks.9.mlp.lin1.bias, torch.Size([3072])\n",
      "blocks.9.mlp.lin1.weight, torch.Size([3072, 768])\n",
      "blocks.9.mlp.lin2.bias, torch.Size([768])\n",
      "blocks.9.mlp.lin2.weight, torch.Size([768, 3072])\n",
      "blocks.9.norm1.bias, torch.Size([768])\n",
      "blocks.9.norm1.weight, torch.Size([768])\n",
      "blocks.9.norm2.bias, torch.Size([768])\n",
      "blocks.9.norm2.weight, torch.Size([768])\n",
      "neck.0.weight, torch.Size([256, 768, 1, 1])\n",
      "neck.1.bias, torch.Size([256])\n",
      "neck.1.weight, torch.Size([256])\n",
      "neck.2.weight, torch.Size([256, 256, 3, 3])\n",
      "neck.3.bias, torch.Size([256])\n",
      "neck.3.weight, torch.Size([256])\n",
      "net_2.weight, torch.Size([512, 256, 3, 3])\n",
      "net_3.weight, torch.Size([1024, 512, 3, 3])\n",
      "patch_embed.proj.bias, torch.Size([768])\n",
      "patch_embed.proj.weight, torch.Size([768, 3, 16, 16])\n",
      "pos_embed, torch.Size([1, 64, 64, 768])\n"
     ]
    }
   ],
   "source": [
    "for k in sorted(sam_model_state_dict.keys()):\n",
    "    print(f\"{k}, {sam_model_state_dict[k].shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
