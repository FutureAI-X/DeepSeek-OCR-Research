{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b5c975",
   "metadata": {},
   "source": [
    "加载依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6e2dbc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BasicImageTransform' from 'image_handle' (/home/guoteng/code/DeepSeek-OCR-Research/reproduct/image_handle.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmessage_handle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_conversation, apply_sft_template\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimage_handle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_pil_images, BasicImageTransform\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtoken_handle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m text_encode\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BasicImageTransform' from 'image_handle' (/home/guoteng/code/DeepSeek-OCR-Research/reproduct/image_handle.py)"
     ]
    }
   ],
   "source": [
    "from message_handle import build_conversation, apply_sft_template\n",
    "from image_handle import load_pil_images, BasicImageTransform\n",
    "from token_handle import text_encode\n",
    "from transformers import AutoTokenizer\n",
    "from PIL import ImageOps\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051cf349",
   "metadata": {},
   "source": [
    "定义输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6001aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"<image>\\nExtract the text in the image.\"     # 用户输入的Prompt\n",
    "image_file = 'tengwangge.png'               # 图片文件\n",
    "base_size = 512                             # TODO\n",
    "image_size = 512                            # TODO\n",
    "crop_mode = False                            # 是否使用裁减模式\n",
    "model_path = \"/home/guoteng/code/DeepSeek-OCR-Research/model_file\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "patch_size = 16                             # 每个 patch 的像素大小\n",
    "downsample_ratio = 4                        # 下采样比例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a7b645",
   "metadata": {},
   "source": [
    "处理prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ee3292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<image>\\nExtract the text in the image.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = build_conversation(prompt, image_file)\n",
    "prompt = apply_sft_template(conversation, sft_format='plain', system_prompt='')\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dbc8ed",
   "metadata": {},
   "source": [
    "对prompt中图像占位进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04b420b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '\\nExtract the text in the image.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_token = '<image>'\n",
    "image_token_id = 128815\n",
    "text_splits = prompt.split(image_token)\n",
    "text_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb234c72",
   "metadata": {},
   "source": [
    "加载图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed772a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = load_pil_images(conversation)\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dbfdad",
   "metadata": {},
   "source": [
    "计算第一张图像的宽高比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10906d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_draw = images[0].copy()\n",
    "w, h = image_draw.size\n",
    "ratio = 1 - ((max(w, h) - min(w, h)) / (max(w, h)))\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686c8e3",
   "metadata": {},
   "source": [
    "循环处理每张图片和它之前的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73896632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directly resize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在现有的浏览器会话中打开。\n"
     ]
    }
   ],
   "source": [
    "tokenized_str = []\n",
    "images_seq_mask = []\n",
    "images_list = []\n",
    "images_spatial_crop = []    # 图像裁剪数量\n",
    "image_transform=BasicImageTransform(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), normalize=True)\n",
    "valid_img_tokens = 0\n",
    "\n",
    "for text_sep, image in zip(text_splits, images):\n",
    "    tokenized_sep = text_encode(tokenizer, text_sep, bos=False, eos=False)\n",
    "    tokenized_str += tokenized_sep\n",
    "    images_seq_mask += [False] * len(tokenized_sep)\n",
    "\n",
    "    if crop_mode:\n",
    "        print(\"Error, Do not support crop mode\")\n",
    "    else:\n",
    "        \"\"\"process the global view\"\"\"\n",
    "        # 1. 如果image_size <= 640, 直接resize\n",
    "        if image_size <= 640:\n",
    "            print('directly resize')\n",
    "            image = image.resize((image_size, image_size))\n",
    "\n",
    "        # 2. 对图像进行填充，保持原始宽高比\n",
    "        global_view = ImageOps.pad(image, (image_size, image_size),\n",
    "                                        color=tuple(int(x * 255) for x in image_transform.mean))\n",
    "        # 3. 将图像转换为Tensor\n",
    "        images_list.append(image_transform(global_view).to(torch.bfloat16))\n",
    "\n",
    "        # 4. 根据base_size设置有效tokens数量\n",
    "        # 对于较小的尺寸使用固定值，而对于较大的尺寸根据 ratio 进行调整\n",
    "        if base_size == 1024:\n",
    "            valid_img_tokens += int(256 * ratio)\n",
    "        elif base_size == 1280:\n",
    "            valid_img_tokens += int(400 * ratio)\n",
    "        elif base_size == 640:\n",
    "            valid_img_tokens += int(100 * 1)\n",
    "        elif base_size == 512:\n",
    "            valid_img_tokens += int(64 * 1)\n",
    "        \n",
    "        # 由于未使用裁剪模式，所以宽度和高度的裁剪数量都设为1\n",
    "        width_crop_num, height_crop_num = 1, 1\n",
    "        images_spatial_crop.append([width_crop_num, height_crop_num])\n",
    "\n",
    "        \"\"\"add image tokens\"\"\"\n",
    "        num_queries = math.ceil((image_size // patch_size) / downsample_ratio)\n",
    "        tokenized_image = ([image_token_id] * num_queries + [image_token_id]) * num_queries\n",
    "        tokenized_image += [image_token_id]\n",
    "        tokenized_str += tokenized_image\n",
    "        images_seq_mask += [True] * len(tokenized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6be3bb",
   "metadata": {},
   "source": [
    "处理最后一个文本段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a515ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"process the last text split\"\"\"\n",
    "tokenized_sep = text_encode(tokenizer, text_splits[-1], bos=False, eos=False)\n",
    "tokenized_str += tokenized_sep\n",
    "images_seq_mask += [False] * len(tokenized_sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b97c8a",
   "metadata": {},
   "source": [
    "添加bos token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"add the bos tokens\"\"\"\n",
    "bos_id = 0\n",
    "tokenized_str = [bos_id] + tokenized_str \n",
    "images_seq_mask = [False] + images_seq_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c72aeec",
   "metadata": {},
   "source": [
    "将输入转换为张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将token list 转换为张量\n",
    "input_ids = torch.LongTensor(tokenized_str)\n",
    "# 图像掩码，为True的位置是图像token的位置\n",
    "images_seq_mask = torch.tensor(images_seq_mask, dtype=torch.bool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseek-ocr-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
